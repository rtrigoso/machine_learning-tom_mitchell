# ğŸ“˜ Chapter 1: Introduction to Machine Learning

---

## 1. What is Machine Learning?

* **Goal:** Programs that improve automatically with experience.

* **Definition (Mitchell, 1997):**

  > A program learns from **experience (E)**, with respect to **tasks (T)** and a **performance measure (P)**, if its performance at T, measured by P, improves with E.

* **Applications:**

  * Speech recognition
  * Fraud detection
  * Self-driving cars
  * Games (checkers, backgammon)
  * Data mining (medical, finance, astronomy)

---

## 2. Well-Posed Learning Problems

* Need to specify:

  1. **Task (T)**
  2. **Performance measure (P)**
  3. **Training experience (E)**

**Example â€“ Checkers**

* T: Playing checkers
* P: % of games won
* E: Self-play games

---

## 3. Designing a Learning System (Checkers Example ğŸ)

### Step 1 â€“ Training Experience

* **Direct feedback** (easier): correct move for each state.
* **Indirect feedback** (harder): only final game outcome (win/lose).
* **Danger:** Training â‰  test distribution â†’ poor generalization.

### Step 2 â€“ Target Function

* Option A: **ChooseMove(board) â†’ best move** (hard).
* Option B: **V(board) â†’ numeric score** (better).

  * Higher = better board state.
  * Choose move â†’ leads to best successor state.

### Step 3 â€“ Representation

* **Linear function of features:**

  ```
  V(b) = w0 + w1x1 + w2x2 + â€¦ + w6x6
  ```

  * x1: # black pieces
  * x2: # red pieces
  * x3: # black kings
  * x4: # red kings
  * x5: black pieces threatened
  * x6: red pieces threatened

ğŸ‘‰ Learning reduces to **finding weights (wâ€™s).**

### Step 4 â€“ Learning Algorithm

* **Need examples (b, Vtrain(b))**.
* Problem: only know final result â†’ estimate intermediate values:

  ```
  Vtrain(b) â‰ˆ V(successor(b))
  ```
* **LMS rule (Least Mean Squares):**

  * For each training example:

    ```
    wi â† wi + Î· (Vtrain(b) â€“ V(b)) xi
    ```

    where Î· = learning rate.
* Equivalent to **stochastic gradient descent**.

---

## 4. Final Design â€“ 4 Modules

```
[ Experiment Generator ] â†’ picks new problems (e.g., self-play)
            â†“
[ Performance System ] â†’ plays checkers using learned V
            â†“
[ Critic ] â†’ evaluates games, produces training examples
            â†“
[ Generalizer ] â†’ learns hypothesis (updates weights)
```

---

## 5. Perspectives on Machine Learning

* **Learning = search** through hypothesis space.
* Different algorithms = different hypothesis representations:

  * Linear functions
  * Decision trees
  * Neural networks
  * Probabilistic models

---

## 6. Key Issues in ML

* Which algorithms converge?
* How much training data is enough?
* How to use prior knowledge?
* How to pick/generate training data?
* How to represent target functions?
* Can representation evolve automatically?

---

## 7. Chapter Summary

* Machine learning = **experience â†’ improved performance**.
* Need: **Task, Performance, Experience**.
* Design involves:

  1. Training experience
  2. Target function
  3. Representation
  4. Algorithm
* Learning = **hypothesis space search**.
* Applications: data mining, adaptation, complex tasks.

---

âœ… **Formulas to Remember**

* **Linear evaluation function:**

  ```
  V(b) = w0 + Î£ wi xi
  ```
* **LMS weight update rule:**

  ```
  wi â† wi + Î· (Vtrain(b) â€“ V(b)) xi
  ```

---

âœ… **Quick Diagram (Learning Loop)**

```
Training Experience â†’ Critic â†’ Training Examples
                                â†“
Experiment Generator â†’ Performance System â†’ Game Trace
                                â†“
                        Generalizer â†’ Hypothesis (f)
```

---

# ğŸ“˜ Study Guide: Chapter 3 â€” Decision Tree Learning

---

## ğŸŒ³ 1. What is Decision Tree Learning?

* **Definition**: A method for approximating **discrete-valued target functions** using a tree structure.
* **Representation**:

  * Each **internal node** â†’ tests an attribute.
  * Each **branch** â†’ possible value of that attribute.
  * Each **leaf** â†’ classification result (Yes/No, category label, etc.).
* **Readable**: Can be converted into a set of **ifâ€“then rules**.
* **Use cases**: medical diagnosis, credit risk, equipment fault detection.

ğŸ” Example: *PlayTennis* dataset (attributes: Outlook, Humidity, Windâ€¦ â†’ target: PlayTennis).

---

## ğŸ¯ 2. When to Use Decision Trees (Appropriate Problems)

* Instances are **attribute-value pairs** (e.g., Humidity = High).
* Target function has **discrete output values** (e.g., Yes/No).
* **Disjunctive concepts** possible (OR-combinations of conditions).
* **Noise tolerant** â†’ can handle misclassified or missing data.
* Works well for **classification problems**.

---

## âš™ï¸ 3. The ID3 Algorithm (Core Decision Tree Algorithm)

* **Strategy**: Top-down, greedy search for the best attribute at each node.
* **Steps**:

  1. Start with all training examples at root.
  2. Pick the attribute with **highest Information Gain**.
  3. Split dataset on that attribute.
  4. Recurse on each branch until:

     * All examples at node are of the same class (pure), or
     * No attributes remain.

ğŸ“Œ **Key Definitions**:

* **Entropy** (measure of impurity):

  $$
  Entropy(S) = -p_+ \log_2(p_+) - p_- \log_2(p_-)
  $$

  * 0 â†’ pure (all same class).
  * 1 â†’ mixed (50/50).

* **Information Gain** (measure of attribute usefulness):

  $$
  Gain(S, A) = Entropy(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} \, Entropy(S_v)
  $$

  * Pick attribute with **highest gain**.

âœ… Example (PlayTennis):

* Best root attribute = **Outlook** (highest info gain).

---

## ğŸ” 4. Hypothesis Space Search

* ID3 searches the space of **all possible decision trees**.
* Expressive enough for any finite discrete function.
* Uses **greedy, hill-climbing search** (no backtracking).
* **Pros**: Efficient, noise-tolerant.
* **Cons**: Might find only a *locally optimal* tree, not the best possible one.

---

## ğŸ§  5. Inductive Bias of Decision Trees

* **Bias** = preference for:

  * **Shorter trees** over longer ones.
  * Trees with **high-information-gain attributes near the root**.
* Related to **Occamâ€™s Razor**: prefer simpler hypotheses that fit the data.
* Type of bias:

  * **Preference bias** (not restricting hypothesis space, but preferring some solutions).

---

## âš ï¸ 6. Issues in Decision Tree Learning

### (a) Overfitting

* **Definition**: Hypothesis fits training data very well but performs poorly on unseen data.
* **Causes**:

  * Noise in training data.
  * Too few examples (coincidental patterns).
* **Solutions**:

  * **Pre-pruning**: stop tree growth early.
  * **Post-pruning**: grow full tree, then remove branches that donâ€™t improve test accuracy.

### (b) Continuous Attributes

* Can be handled by splitting with thresholds (e.g., Temp > 75).

### (c) Missing Data

* Strategies: ignore example, assign most probable value, or distribute among branches.

### (d) Attribute Costs

* Some attributes may be expensive to measure â†’ modify gain formula to account for cost.

---

## ğŸ“ 7. Key Takeaways

* Decision trees are intuitive, interpretable, and widely used.
* **ID3 algorithm** builds them using entropy + information gain.
* Hypothesis space = all finite discrete functions â†’ very powerful.
* Bias = prefers smaller, simpler trees (Occamâ€™s Razor).
* Main risk = **overfitting**, solved with pruning.

---
